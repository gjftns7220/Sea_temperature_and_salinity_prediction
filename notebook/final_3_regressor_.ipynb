{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAdEMSoJ7Z30"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrA7vqN67e4p",
        "outputId": "0ac4dcf4-4f0f-4d05-ca5b-d8f1dd12712c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EtIi0e0_7c5r",
        "outputId": "ff8af50c-2c0c-4893-9566-754b40ddea09"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntest = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Batch/data_after_2020.csv')\\ntest_time = test[['time']]\\ntest_features = test[['depth', 'year', 'month', 'day', 'latitude', 'longitude']]\\ntest_targets = test[['sea_water_temperature', 'sea_water_practical_salinity']]\\n\""
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Batch/data_after_2020.csv')\n",
        "test_time = test[['time']]\n",
        "test_features = test[['depth', 'year', 'month', 'day', 'latitude', 'longitude']]\n",
        "test_targets = test[['sea_water_temperature', 'sea_water_practical_salinity']]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "r0fKMqIH7Z32",
        "outputId": "40bf519f-2e43-4aa7-e11a-829c611e8fba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nscaler = StandardScaler()\\n\\nfor i in range(1, 11):\\n\\n    train = pd.read_csv(f\\'/content/drive/MyDrive/Colab Notebooks/Batch/batch_{i}.csv\\')\\n    train_features = train[[\\'depth\\', \\'year\\', \\'month\\', \\'day\\', \\'latitude\\', \\'longitude\\']]\\n    train_targets = train[[\\'sea_water_temperature\\', \\'sea_water_practical_salinity\\']]\\n\\n\\n    X_train_scaled = scaler.fit_transform(train_features)\\n    y_train = train_targets\\n    X_test_scaled = scaler.transform(test_features)\\n    y_test = test_targets\\n\\n\\n    model = RandomForestRegressor(n_estimators=100, random_state=42)\\n    model.fit(X_train_scaled, y_train)\\n\\n\\n    y_pred = model.predict(X_test_scaled)\\n\\n    mse = mean_squared_error(y_test, y_pred)\\n    rmse = np.sqrt(mse)\\n    mae = mean_absolute_error(y_test, y_pred)\\n    print(f\"Batch {i} - RMSE: {rmse}, MAE: {mae}\")\\n\\n\\n    y_test_df = pd.DataFrame(y_test.values, columns=[\\'actual_temperature\\', \\'actual_salinity\\'])\\n    unscaled_features_df = pd.DataFrame(test_features).reset_index(drop=True)\\n    time_test_df = pd.DataFrame(test_time.values, columns=[\\'date\\'])\\n    preds_df = pd.DataFrame(y_pred, columns=[\\'predicted_temperature\\', \\'predicted_salinity\\'])\\n    results_df = pd.concat([time_test_df, unscaled_features_df, y_test_df, preds_df], axis=1)\\n    results_csv_path = f\\'/content/drive/MyDrive/Colab Notebooks/Batch/prediction_{i}.csv\\'\\n    results_df.to_csv(results_csv_path, index=False)\\n    '"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in range(1, 11):\n",
        "\n",
        "    train = pd.read_csv(f'/content/drive/MyDrive/Colab Notebooks/Batch/batch_{i}.csv')\n",
        "    train_features = train[['depth', 'year', 'month', 'day', 'latitude', 'longitude']]\n",
        "    train_targets = train[['sea_water_temperature', 'sea_water_practical_salinity']]\n",
        "\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(train_features)\n",
        "    y_train = train_targets\n",
        "    X_test_scaled = scaler.transform(test_features)\n",
        "    y_test = test_targets\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    print(f\"Batch {i} - RMSE: {rmse}, MAE: {mae}\")\n",
        "\n",
        "\n",
        "    y_test_df = pd.DataFrame(y_test.values, columns=['actual_temperature', 'actual_salinity'])\n",
        "    unscaled_features_df = pd.DataFrame(test_features).reset_index(drop=True)\n",
        "    time_test_df = pd.DataFrame(test_time.values, columns=['date'])\n",
        "    preds_df = pd.DataFrame(y_pred, columns=['predicted_temperature', 'predicted_salinity'])\n",
        "    results_df = pd.concat([time_test_df, unscaled_features_df, y_test_df, preds_df], axis=1)\n",
        "    results_csv_path = f'/content/drive/MyDrive/Colab Notebooks/Batch/prediction_{i}.csv'\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrTvrO-xCnqc",
        "outputId": "1822e3f4-1fa5-4304-c23f-7ef9e142e85d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm xgboost catboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD9J6XRJCsGp",
        "outputId": "75bc6434-004f-48ea-8064-e86886863fb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105307 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 856\n",
            "[LightGBM] [Info] Number of data points in the train set: 11532367, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 7.896171\n",
            "Model: LightGBM, sea_water_temperature - RMSE: 0.7584171186391223, MAE: 0.5834229532027849\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105352 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 856\n",
            "[LightGBM] [Info] Number of data points in the train set: 11532367, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 32.316673\n",
            "Model: LightGBM, sea_water_practical_salinity - RMSE: 0.546878050923362, MAE: 0.29783574893270165\n",
            "Model: XGBoost, sea_water_temperature - RMSE: 0.7495092424821291, MAE: 0.5633850559280934\n",
            "Model: XGBoost, sea_water_practical_salinity - RMSE: 0.5286607474574955, MAE: 0.2958294314341395\n",
            "Model: CatBoost, sea_water_temperature - RMSE: 0.7106893659468779, MAE: 0.5365097724929564\n",
            "Model: CatBoost, sea_water_practical_salinity - RMSE: 0.5254488869584168, MAE: 0.2967557370010345\n"
          ]
        }
      ],
      "source": [
        "\n",
        "scaler = StandardScaler()\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Batch/data_after_2020.csv')\n",
        "test_time = test[['time']]\n",
        "test_features = test[['depth', 'year', 'month', 'day', 'latitude', 'longitude']]\n",
        "test_targets = test[['sea_water_temperature', 'sea_water_practical_salinity']]\n",
        "\n",
        "model_classes = {\n",
        "    #\"HistGradientBoosting\": HistGradientBoostingRegressor(random_state=42),\n",
        "    \"LightGBM\": LGBMRegressor(random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(random_state=42),\n",
        "    \"CatBoost\": CatBoostRegressor(verbose=0, random_state=42)\n",
        "}\n",
        "\n",
        "for model_name, model in model_classes.items():\n",
        "    for target_col in test_targets.columns:\n",
        "            train = pd.read_csv(f'/content/drive/MyDrive/Colab Notebooks/data_before_2020.csv')\n",
        "            train['time'] = pd.to_datetime(train['time'])\n",
        "            train_features = train[['depth', 'year', 'month', 'day', 'latitude', 'longitude']]\n",
        "            train_targets = train[target_col]\n",
        "\n",
        "\n",
        "            X_train_scaled = scaler.fit_transform(train_features)\n",
        "            y_train = train_targets\n",
        "            X_test_scaled = scaler.transform(test_features)\n",
        "            y_test = test_targets[target_col]\n",
        "\n",
        "            model.fit(X_train_scaled, train_targets)\n",
        "\n",
        "\n",
        "            y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            print(f\"Model: {model_name}, {target_col} - RMSE: {rmse}, MAE: {mae}\")\n",
        "\n",
        "            y_test_df = pd.DataFrame(y_test.values, columns=[f'actual_{target_col}'])\n",
        "            unscaled_features_df = pd.DataFrame(test_features).reset_index(drop=True)\n",
        "            time_test_df = pd.DataFrame(test_time.values, columns=['date'])\n",
        "            preds_df = pd.DataFrame(y_pred, columns=[f'predicted_{target_col}'])\n",
        "            results_df = pd.concat([time_test_df, unscaled_features_df, y_test_df, preds_df], axis=1)\n",
        "            results_csv_path = f'/content/drive/MyDrive/Colab Notebooks/Batch/{model_name}_{target_col}_prediction_whole_minmax.csv'\n",
        "            results_df.to_csv(results_csv_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmFIAc4mwKrl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "for model_name, model in model_classes.items():\n",
        "    for target_col in test_targets.columns:\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"Model: {model_name}, {target_col} - RMSE: {rmse}, MAE: {mae}, R^2: {r2}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bDSSqN_pD3d"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "scaler = MinMaxScalar()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/sampled_with_dates.csv'\n",
        "test = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "test['random_date'] = pd.to_datetime(test['random_date'])\n",
        "test['year'] = test['random_date'].dt.year\n",
        "test['month'] = test['random_date'].dt.month\n",
        "test['day'] = test['random_date'].dt.day\n",
        "\n",
        "test_features = test[['depth', 'year', 'month', 'day', 'latitude', 'longitude']]\n",
        "\n",
        "\n",
        "model_classes = {\n",
        "    \"LightGBM\": LGBMRegressor(random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(random_state=42),\n",
        "    \"CatBoost\": CatBoostRegressor(verbose=0, random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "test_targets = ['sea_water_temperature', 'sea_water_practical_salinity']\n",
        "\n",
        "\n",
        "for model_name, model in model_classes.items():\n",
        "    for target_col in test_targets:\n",
        "\n",
        "        train = pd.read_csv(f'/content/drive/MyDrive/Colab Notebooks/more_clean_ver.csv')\n",
        "        train['time'] = pd.to_datetime(train['time'])\n",
        "        train['year'] = train['time'].dt.year\n",
        "        train['month'] = train['time'].dt.month\n",
        "        train['day'] = train['time'].dt.day\n",
        "        train_features = train[['depth', 'year', 'month', 'day', 'latitude', 'longitude']]\n",
        "        train_targets = train[target_col]\n",
        "\n",
        "\n",
        "        X_train_scaled = scaler.fit_transform(train_features)\n",
        "        X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "\n",
        "        model.fit(X_train_scaled, train_targets)\n",
        "\n",
        "\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "        unscaled_features_df = pd.DataFrame(test_features).reset_index(drop=True)\n",
        "        time_test_df = pd.DataFrame(test[['random_date']].values, columns=['date'])\n",
        "        preds_df = pd.DataFrame(y_pred, columns=[f'predicted_{target_col}'])\n",
        "        results_df = pd.concat([time_test_df, unscaled_features_df, preds_df], axis=1)\n",
        "        results_csv_path = f'/content/drive/MyDrive/Colab Notebooks/Batch/{model_name}_{target_col}_prediction_whole222.csv'\n",
        "        results_df.to_csv(results_csv_path, index=False)\n",
        "\n",
        "print(\"Predictions completed and saved.\")\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
